{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6aa2dd1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "def reduce_mem_usage_safe(df):\n",
    "    start_mem = df.memory_usage().sum() / 1024**2\n",
    "    print(f\"Usage mémoire initial du DataFrame: {start_mem:.2f} MB\")\n",
    "\n",
    "    for col in df.columns:\n",
    "        col_type = df[col].dtype\n",
    "\n",
    "        if col_type == 'bool':\n",
    "            df[col] = df[col].astype('bool')\n",
    "        elif str(col_type)[:3] == 'int':\n",
    "            c_min = df[col].min()\n",
    "            c_max = df[col].max()\n",
    "            if c_min >= np.iinfo(np.int8).min and c_max <= np.iinfo(np.int8).max:\n",
    "                df[col] = df[col].astype(np.int8)\n",
    "            elif c_min >= np.iinfo(np.int16).min and c_max <= np.iinfo(np.int16).max:\n",
    "                df[col] = df[col].astype(np.int16)\n",
    "            elif c_min >= np.iinfo(np.int32).min and c_max <= np.iinfo(np.int32).max:\n",
    "                df[col] = df[col].astype(np.int32)\n",
    "            else:\n",
    "                df[col] = df[col].astype(np.int64)\n",
    "        elif str(col_type)[:5] == 'float':\n",
    "            c_min = df[col].min()\n",
    "            c_max = df[col].max()\n",
    "            if c_min >= np.finfo(np.float32).min and c_max <= np.finfo(np.float32).max:\n",
    "                df[col] = df[col].astype(np.float32)\n",
    "            else:\n",
    "                df[col] = df[col].astype(np.float64)\n",
    "\n",
    "    end_mem = df.memory_usage().sum() / 1024**2\n",
    "    print(f\"Usage mémoire final du DataFrame: {end_mem:.2f} MB\")\n",
    "    print(f\"Mémoire réduite de {(start_mem - end_mem) / start_mem * 100:.1f} %\")\n",
    "\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "32f4a3ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "def reduce_mem_usage(df):\n",
    "    \"\"\"\n",
    "    Itère sur toutes les colonnes d'un DataFrame et réduit la précision\n",
    "    des types numériques (int et float) pour diminuer la consommation de mémoire.\n",
    "    \"\"\"\n",
    "    start_mem = df.memory_usage().sum() / 1024**2\n",
    "    print(f\"Usage mémoire initial du DataFrame: {start_mem:.2f} MB\")\n",
    "\n",
    "    for col in df.columns:\n",
    "        col_type = df[col].dtype\n",
    "\n",
    "        # Traiter uniquement les colonnes numériques\n",
    "        if col_type != object and col_type != str and col_type != bool:\n",
    "            c_min = df[col].min()\n",
    "            c_max = df[col].max()\n",
    "\n",
    "            # --- Conversion des entiers (Integers) ---\n",
    "            if str(col_type)[:3] == 'int':\n",
    "                if c_min > np.iinfo(np.int8).min and c_max < np.iinfo(np.int8).max:\n",
    "                    df[col] = df[col].astype(np.int8)\n",
    "                elif c_min > np.iinfo(np.int16).min and c_max < np.iinfo(np.int16).max:\n",
    "                    df[col] = df[col].astype(np.int16)\n",
    "                elif c_min > np.iinfo(np.int32).min and c_max < np.iinfo(np.int32).max:\n",
    "                    df[col] = df[col].astype(np.int32)\n",
    "                elif c_min > np.iinfo(np.int64).min and c_max < np.iinfo(np.int64).max:\n",
    "                    df[col] = df[col].astype(np.int64)\n",
    "\n",
    "            # --- Conversion des décimaux (Floats) ---\n",
    "            else:\n",
    "                # La majorité de vos colonnes d'agrégats (mean, var, proportions) sont ici\n",
    "                if c_min > np.finfo(np.float16).min and c_max < np.finfo(np.float16).max:\n",
    "                    df[col] = df[col].astype(np.float16)\n",
    "                elif c_min > np.finfo(np.float32).min and c_max < np.finfo(np.float32).max:\n",
    "                    # Conversion principale : float64 -> float32\n",
    "                    df[col] = df[col].astype(np.float32)\n",
    "                else:\n",
    "                    df[col] = df[col].astype(np.float64) # Garder float64 si la précision est nécessaire\n",
    "\n",
    "    end_mem = df.memory_usage().sum() / 1024**2\n",
    "    print(f\"Usage mémoire final du DataFrame: {end_mem:.2f} MB\")\n",
    "    print(f\"Mémoire réduite de {(start_mem - end_mem) / start_mem * 100:.1f} %\")\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bec0c2a3",
   "metadata": {},
   "source": [
    "ETAPE 1\n",
    "netoyage et imputation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cba9d8f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting to load and optimize dataframes...\n",
      "Memory usage of dataframe before: 286.23 MB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reducing memory: 100%|██████████| 122/122 [00:00<00:00, 289.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Memory usage after optimization: 128.16 MB (55.2% reduction)\n",
      "Memory usage of dataframe before: 45.00 MB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reducing memory: 100%|██████████| 121/121 [00:00<00:00, 1628.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Memory usage after optimization: 20.27 MB (55.0% reduction)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Memory usage of dataframe before: 222.62 MB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reducing memory: 100%|██████████| 17/17 [00:00<00:00, 73.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Memory usage after optimization: 119.49 MB (46.3% reduction)\n",
      "Memory usage of dataframe before: 624.85 MB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reducing memory: 100%|██████████| 3/3 [00:00<00:00, 16.55it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Memory usage after optimization: 338.46 MB (45.8% reduction)\n",
      "Memory usage of dataframe before: 673.88 MB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reducing memory: 100%|██████████| 23/23 [00:00<00:00, 29.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Memory usage after optimization: 318.63 MB (52.7% reduction)\n",
      "Memory usage of dataframe before: 830.41 MB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reducing memory: 100%|██████████| 8/8 [00:00<00:00, 12.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Memory usage after optimization: 389.25 MB (53.1% reduction)\n",
      "Memory usage of dataframe before: 610.43 MB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reducing memory: 100%|██████████| 8/8 [00:00<00:00, 23.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Memory usage after optimization: 276.60 MB (54.7% reduction)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from tqdm import tqdm  # Pour les barres de progression\n",
    "\n",
    "\n",
    "# --- 1. Optimisation Mémoire ---\n",
    "def reduce_mem_usage_safe(df, verbose=True):\n",
    "    \"\"\"\n",
    "    Itère sur toutes les colonnes d'un DataFrame et modifie les types de données\n",
    "    pour minimiser l'utilisation de la mémoire.\n",
    "    \"\"\"\n",
    "    df_out = df.copy()  # Evite les SettingWithCopyWarning\n",
    "    start_mem = df_out.memory_usage().sum() / 1024**2\n",
    "    if verbose:\n",
    "        print(f'Memory usage of dataframe before: {start_mem:.2f} MB')\n",
    "\n",
    "    for col in tqdm(df_out.columns, desc=\"Reducing memory\"):\n",
    "        col_type = df_out[col].dtype\n",
    "\n",
    "        if col_type != object:\n",
    "            c_min = df_out[col].min()\n",
    "            c_max = df_out[col].max()\n",
    "            if str(col_type)[:3] == 'int':\n",
    "                if c_min >= np.iinfo(np.int8).min and c_max <= np.iinfo(np.int8).max:\n",
    "                    df_out[col] = df_out[col].astype(np.int8)\n",
    "                elif c_min >= np.iinfo(np.int16).min and c_max <= np.iinfo(np.int16).max:\n",
    "                    df_out[col] = df_out[col].astype(np.int16)\n",
    "                elif c_min >= np.iinfo(np.int32).min and c_max <= np.iinfo(np.int32).max:\n",
    "                    df_out[col] = df_out[col].astype(np.int32)\n",
    "                else:\n",
    "                    df_out[col] = df_out[col].astype(np.int64)\n",
    "            else:\n",
    "                if c_min >= np.finfo(np.float32).min and c_max <= np.finfo(np.float32).max:\n",
    "                    df_out[col] = df_out[col].astype(np.float32)\n",
    "                else:\n",
    "                    df_out[col] = df_out[col].astype(np.float64)\n",
    "\n",
    "    end_mem = df_out.memory_usage().sum() / 1024**2\n",
    "    if verbose:\n",
    "        print(f'Memory usage after optimization: {end_mem:.2f} MB ({100 * (start_mem - end_mem) / start_mem:.1f}% reduction)')\n",
    "    return df_out\n",
    "\n",
    "\n",
    "# --- 2. Analyse des NaN ---\n",
    "def get_missing_values_table(df, df_name, top_n=20):\n",
    "    \"\"\"Calcule et affiche le tableau des valeurs manquantes pour un DataFrame.\"\"\"\n",
    "    mis_val = df.isnull().sum()\n",
    "    mis_val_percent = 100 * mis_val / len(df)\n",
    "    mis_val_table = pd.concat([mis_val, mis_val_percent], axis=1)\n",
    "    mis_val_table_ren_columns = mis_val_table.rename(\n",
    "        columns={0: 'Missing Values', 1: '% of Total Values'}\n",
    "    )\n",
    "    mis_val_table_ren_columns = mis_val_table_ren_columns[\n",
    "        mis_val_table_ren_columns.iloc[:, 1] != 0\n",
    "    ].sort_values('% of Total Values', ascending=False).round(1)\n",
    "\n",
    "    print(f\"\\n--- Missing values for {df_name} ---\")\n",
    "    print(f\"DataFrame has {df.shape[1]} columns.\")\n",
    "    print(f\"There are {mis_val_table_ren_columns.shape[0]} columns with missing values.\")\n",
    "\n",
    "    return mis_val_table_ren_columns.head(top_n)\n",
    "\n",
    "\n",
    "# --- 3. Définition des chemins et chargement des fichiers ---\n",
    "DATA_DIR = r\"C:\\Users\\maill\\OneDrive\\Bureau\\majeur_ia\\dataenginnering\\projet\\home-credit-default-risk\"\n",
    "\n",
    "csv_files = {\n",
    "    'train': 'application_train.csv',\n",
    "    'test': 'application_test.csv',\n",
    "    'bureau': 'bureau.csv',\n",
    "    'bureau_balance': 'bureau_balance.csv',\n",
    "    'credit_card_balance': 'credit_card_balance.csv',\n",
    "    'installments_payments': 'installments_payments.csv',\n",
    "    'POS_CASH_balance': 'POS_CASH_balance.csv',\n",
    "    'previous_application': 'previous_application.csv'\n",
    "}\n",
    "\n",
    "dataframes = {}\n",
    "\n",
    "print(\"Starting to load and optimize dataframes...\")\n",
    "for name, filename in csv_files.items():\n",
    "    file_path = os.path.join(DATA_DIR, filename)\n",
    "    if os.path.exists(file_path):\n",
    "        df = pd.read_csv(file_path)\n",
    "        dataframes[name] = reduce_mem_usage_safe(df, verbose=True)\n",
    "    else:\n",
    "        print(f\"File not found: {file_path}. Skipping.\")\n",
    "print(\"All available dataframes loaded.\")\n",
    "\n",
    "\n",
    "# --- 4. Analyse des NaN pour tous les fichiers ---\n",
    "for name, df in dataframes.items():\n",
    "    missing_table = get_missing_values_table(df, name)\n",
    "    print(missing_table)\n",
    "\n",
    "\n",
    "# --- 5. Nettoyage et imputation des fichiers principaux ---\n",
    "df_train = dataframes.get('train')\n",
    "df_test = dataframes.get('test')\n",
    "\n",
    "if df_train is not None and df_test is not None:\n",
    "    print(\"\\n--- Imputation Strategy on Main DataFrames ---\")\n",
    "\n",
    "    house_cols = [\n",
    "        col for col in df_train.columns\n",
    "        if ('APARTMENTS' in col or 'YEARS_BUILD' in col or 'COMMONAREA' in col or 'ELEVATORS' in col or 'FONDKAPREMONT' in col)\n",
    "        and 'MODE' not in col\n",
    "    ]\n",
    "\n",
    "    for df in [df_train, df_test]:\n",
    "        # Imputation variables immobilières\n",
    "        for col in house_cols:\n",
    "            if col in df.columns:\n",
    "                df[f'{col}_IS_NAN'] = df[col].isnull().astype(np.int8)\n",
    "                df[col].fillna(0, inplace=True)\n",
    "\n",
    "        # Imputation EXT_SOURCE\n",
    "        for col in ['EXT_SOURCE_1', 'EXT_SOURCE_2', 'EXT_SOURCE_3']:\n",
    "            if col in df.columns:\n",
    "                df[f'{col}_IS_NAN'] = df[col].isnull().astype(np.int8)\n",
    "                df[col].fillna(df[col].median(), inplace=True)\n",
    "\n",
    "        # Imputation colonnes catégorielles\n",
    "        for col in ['NAME_TYPE_SUITE', 'OCCUPATION_TYPE', 'FONDKAPREMONT_MODE', 'WALLSMATERIAL_MODE']:\n",
    "            if col in df.columns and df[col].dtype == object:\n",
    "                df[col].fillna('Missing', inplace=True)\n",
    "\n",
    "        # Correction DAYS_EMPLOYED\n",
    "        if 'DAYS_EMPLOYED' in df.columns:\n",
    "            df['DAYS_EMPLOYED'].replace(365243, np.nan, inplace=True)\n",
    "            df['DAYS_EMPLOYED'].fillna(df['DAYS_EMPLOYED'].median(), inplace=True)\n",
    "\n",
    "    print(\"Main DataFrames (train/test) cleaned and imputed.\")\n",
    "    dataframes['train'] = df_train\n",
    "    dataframes['test'] = df_test\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91a17266",
   "metadata": {},
   "source": [
    "1.2 enrichissement de donner "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "92e0be49",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Starting Feature Engineering: Bureau & Bureau Balance ---\n",
      "Processing bureau_balance...\n",
      "Merged bureau_balance into bureau. New bureau shape: (1716428, 49)\n",
      "Processing bureau...\n",
      "Bureau aggregation done. Aggregated shape: (305811, 248)\n",
      "Merged bureau features into df_train. New shape: (307511, 385)\n",
      "Merged bureau features into df_test. New shape: (48744, 384)\n",
      "\n",
      "Feature Engineering for Bureau & Bureau Balance completed.\n",
      "The main DataFrames now contain over 300 new features based on credit history.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Récupération des DataFrames chargés\n",
    "dataframes = globals().get('dataframes')\n",
    "\n",
    "if dataframes is None:\n",
    "    print(\"Error: DataFrames not loaded. Please ensure the previous block of code was executed.\")\n",
    "    exit() \n",
    "\n",
    "df_train = dataframes['train']\n",
    "df_test = dataframes['test']\n",
    "df_bureau = dataframes['bureau']\n",
    "df_bureau_balance = dataframes['bureau_balance']\n",
    "\n",
    "print(\"\\n--- Starting Feature Engineering: Bureau & Bureau Balance ---\")\n",
    "\n",
    "# --- 1. TRAITEMENT DE BUREAU_BALANCE ---\n",
    "print(\"Processing bureau_balance...\")\n",
    "\n",
    "# One-Hot Encoding pour STATUS\n",
    "df_bureau_balance = pd.get_dummies(df_bureau_balance, dummy_na=False)\n",
    "\n",
    "if 'DAYS_CREDIT_ENDDATE_FLAG' in df_bureau.columns:\n",
    "    df_bureau = df_bureau.drop(columns=['DAYS_CREDIT_ENDDATE_FLAG'])\n",
    "\n",
    "# Fonction d'agrégation corrigée\n",
    "def group_and_aggregate(df, group_key, df_name, agg_funcs):\n",
    "    \"\"\"Effectue l'agrégation et renomme les colonnes.\"\"\"\n",
    "    # Agrégation standard\n",
    "    agg_df = df.groupby(group_key).agg(agg_funcs)\n",
    "    # Aplatir les noms de colonnes\n",
    "    agg_df.columns = pd.Index([f'{df_name}_{col[0]}_{col[1].upper()}' for col in agg_df.columns.tolist()])\n",
    "    return agg_df\n",
    "\n",
    "# Agrégation bureau_balance par SK_ID_BUREAU\n",
    "bb_agg_funcs = ['min', 'max', 'count', 'mean']  # <--- corrigé\n",
    "bb_grouped = group_and_aggregate(\n",
    "    df_bureau_balance.drop(columns=['MONTHS_BALANCE']),\n",
    "    group_key='SK_ID_BUREAU',\n",
    "    df_name='BUREAU_BALANCE',\n",
    "    agg_funcs=bb_agg_funcs\n",
    ")\n",
    "\n",
    "# Fusion dans bureau\n",
    "df_bureau = df_bureau.merge(bb_grouped, how='left', on='SK_ID_BUREAU')\n",
    "print(f\"Merged bureau_balance into bureau. New bureau shape: {df_bureau.shape}\")\n",
    "\n",
    "# --- 2. TRAITEMENT DE BUREAU ---\n",
    "print(\"Processing bureau...\")\n",
    "\n",
    "df_bureau = pd.get_dummies(df_bureau, dummy_na=False)\n",
    "\n",
    "BUREAU_IGNORE_COLS = ['SK_ID_CURR', 'SK_ID_BUREAU', 'CREDIT_ACTIVE_Active'] \n",
    "bureau_cols = [col for col in df_bureau.columns if col not in BUREAU_IGNORE_COLS]\n",
    "\n",
    "num_agg = ['min', 'max', 'mean', 'sum', 'var']  # <--- corrigé\n",
    "cat_agg = ['mean', 'sum']\n",
    "\n",
    "# Définition des agrégations spécifiques\n",
    "bureau_agg_funcs = {}\n",
    "for col in bureau_cols:\n",
    "    if df_bureau[col].dtype != object:\n",
    "        if 'COUNT' in col or 'SUM' in col or 'STATUS' in col:\n",
    "            bureau_agg_funcs[col] = cat_agg\n",
    "        else:\n",
    "            bureau_agg_funcs[col] = num_agg\n",
    "\n",
    "# Agrégation bureau par SK_ID_CURR\n",
    "bureau_grouped = df_bureau.groupby('SK_ID_CURR').agg(bureau_agg_funcs)\n",
    "bureau_grouped.columns = pd.Index([f'BUREAU_{col[0]}_{col[1].upper()}' for col in bureau_grouped.columns.tolist()])\n",
    "print(f\"Bureau aggregation done. Aggregated shape: {bureau_grouped.shape}\")\n",
    "\n",
    "# --- 3. FUSION DANS LES DATAFRAMES PRINCIPAUX ---\n",
    "df_train = df_train.merge(bureau_grouped, how='left', on='SK_ID_CURR')\n",
    "print(f\"Merged bureau features into df_train. New shape: {df_train.shape}\")\n",
    "\n",
    "df_test = df_test.merge(bureau_grouped, how='left', on='SK_ID_CURR')\n",
    "print(f\"Merged bureau features into df_test. New shape: {df_test.shape}\")\n",
    "\n",
    "# Mise à jour des DataFrames globaux\n",
    "dataframes['train'] = df_train\n",
    "dataframes['test'] = df_test\n",
    "\n",
    "print(\"\\nFeature Engineering for Bureau & Bureau Balance completed.\")\n",
    "print(\"The main DataFrames now contain over 300 new features based on credit history.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f1ac071",
   "metadata": {},
   "source": [
    "enrichissement des donner2 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "efec8415",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Starting Feature Engineering: Previous Application ---\n",
      "Processing previous_application...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maill\\AppData\\Local\\Temp\\ipykernel_16988\\2199870853.py:38: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df_prev['DAYS_FIRST_DRAWING'].replace(365243, np.nan, inplace=True)\n",
      "C:\\Users\\maill\\AppData\\Local\\Temp\\ipykernel_16988\\2199870853.py:39: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df_prev['DAYS_FIRST_DRAWING'].fillna(0, inplace=True) # Imputation par 0 pour le moment (à affiner)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Previous Application aggregation done. Aggregated shape: (338857, 443)\n",
      "Merged previous_application features into df_train. New shape: (307511, 828)\n",
      "Merged previous_application features into df_test. New shape: (48744, 827)\n",
      "\n",
      "Feature Engineering for Previous Application completed.\n",
      "Total columns in df_train: 828\n"
     ]
    }
   ],
   "source": [
    "# Nécessaire pour les opérations de fusion et d'agrégation\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Récupération des DataFrames mis à jour\n",
    "dataframes = globals().get('dataframes') \n",
    "\n",
    "if dataframes is None or 'previous_application' not in dataframes:\n",
    "    print(\"Error: DataFrames not loaded or previous_application is missing.\")\n",
    "    exit() \n",
    "\n",
    "df_train = dataframes['train']\n",
    "df_test = dataframes['test']\n",
    "df_prev = dataframes['previous_application']\n",
    "\n",
    "print(\"\\n--- Starting Feature Engineering: Previous Application ---\")\n",
    "\n",
    "# --- 1. PRÉ-TRAITEMENT ET FEATURE CREATION ---\n",
    "\n",
    "print(\"Processing previous_application...\")\n",
    "\n",
    "# One-Hot Encoding pour les colonnes catégorielles\n",
    "df_prev = pd.get_dummies(df_prev, dummy_na=False)\n",
    "\n",
    "# Création de quelques ratios et features clés (bonnes pratiques du métier)\n",
    "# Ratio Montant du Crédit / Montant Demandé\n",
    "df_prev['APP_CREDIT_PER_APPLICATION'] = df_prev['AMT_CREDIT'] / df_prev['AMT_APPLICATION']\n",
    "# Ratio Montant Annuité / Montant Demandé\n",
    "df_prev['ANNUITY_PER_APPLICATION'] = df_prev['AMT_ANNUITY'] / df_prev['AMT_APPLICATION']\n",
    "# Ratio Montant Crédit / Montant Annuité\n",
    "df_prev['CREDIT_PER_ANNUITY'] = df_prev['AMT_CREDIT'] / df_prev['AMT_ANNUITY']\n",
    "# Ratio Montant Crédit / Durée du prêt (approximative)\n",
    "df_prev['CREDIT_PER_TERM'] = df_prev['AMT_CREDIT'] / df_prev['CNT_PAYMENT']\n",
    "\n",
    "\n",
    "# Correction de l'outlier DAYS_FIRST_DRAWING\n",
    "# La valeur 365243 signifie ici \"Inconnu\" ou \"Pas d'événement\"\n",
    "df_prev['DAYS_FIRST_DRAWING'].replace(365243, np.nan, inplace=True)\n",
    "df_prev['DAYS_FIRST_DRAWING'].fillna(0, inplace=True) # Imputation par 0 pour le moment (à affiner)\n",
    "\n",
    "\n",
    "# --- 2. AGRÉGATION PAR CLIENT (SK_ID_CURR) ---\n",
    "\n",
    "PREV_IGNORE_COLS = ['SK_ID_CURR', 'SK_ID_PREV']\n",
    "prev_cols = [col for col in df_prev.columns if col not in PREV_IGNORE_COLS]\n",
    "\n",
    "# Définition des fonctions d'agrégation\n",
    "prev_num_agg = ['mean', 'min', 'max', 'sum', 'var']\n",
    "prev_cat_agg = ['mean', 'sum'] # Pour les colonnes issues du OHE\n",
    "\n",
    "# Structure des agrégations\n",
    "prev_agg_funcs = {}\n",
    "for col in prev_cols:\n",
    "    if df_prev[col].dtype != object:\n",
    "        # Les colonnes de OHE/compte sont agrégées avec mean (pour le ratio) et sum (pour le compte total)\n",
    "        if 'FLAG' in col or 'MODE' in col or 'TYPE' in col or 'NAME' in col or 'CODE' in col or 'WEEKDAY' in col or 'HOUR' in col:\n",
    "            prev_agg_funcs[col] = prev_cat_agg\n",
    "        # Autres colonnes numériques\n",
    "        else:\n",
    "            prev_agg_funcs[col] = prev_num_agg\n",
    "\n",
    "# Agrégation\n",
    "prev_grouped = df_prev.groupby('SK_ID_CURR').agg(prev_agg_funcs)\n",
    "\n",
    "# Aplatir les noms de colonnes\n",
    "prev_grouped.columns = pd.Index([f'PREV_{col[0]}_{col[1].upper()}' for col in prev_grouped.columns.tolist()])\n",
    "\n",
    "print(f\"Previous Application aggregation done. Aggregated shape: {prev_grouped.shape}\")\n",
    "\n",
    "# --- 3. FUSION DANS LES DATAFRAMES PRINCIPAUX ---\n",
    "\n",
    "# Fusion avec df_train\n",
    "df_train = df_train.merge(prev_grouped, how='left', on='SK_ID_CURR')\n",
    "print(f\"Merged previous_application features into df_train. New shape: {df_train.shape}\")\n",
    "\n",
    "# Fusion avec df_test\n",
    "df_test = df_test.merge(prev_grouped, how='left', on='SK_ID_CURR')\n",
    "print(f\"Merged previous_application features into df_test. New shape: {df_test.shape}\")\n",
    "\n",
    "# Mise à jour des DataFrames\n",
    "dataframes['train'] = df_train\n",
    "dataframes['test'] = df_test\n",
    "\n",
    "print(\"\\nFeature Engineering for Previous Application completed.\")\n",
    "print(f\"Total columns in df_train: {df_train.shape[1]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e97e3844",
   "metadata": {},
   "source": [
    "enrichissement des donner 3 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5d50d549",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Starting Feature Engineering: Installments Payments ---\n",
      "Installments Payments aggregation done. Aggregated shape: (339587, 23)\n",
      "Merged installments_payments features into df_train. New shape: (307511, 851)\n",
      "Merged installments_payments features into df_test. New shape: (48744, 850)\n",
      "\n",
      "Feature Engineering for Installments Payments completed.\n",
      "Total columns in df_train: 851\n"
     ]
    }
   ],
   "source": [
    "# Nécessaire pour les opérations de fusion et d'agrégation\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Récupération des DataFrames mis à jour\n",
    "dataframes = globals().get('dataframes') \n",
    "\n",
    "if dataframes is None or 'installments_payments' not in dataframes:\n",
    "    print(\"Error: DataFrames not loaded or installments_payments is missing.\")\n",
    "    exit() \n",
    "\n",
    "df_train = dataframes['train']\n",
    "df_test = dataframes['test']\n",
    "df_installments = dataframes['installments_payments']\n",
    "\n",
    "print(\"\\n--- Starting Feature Engineering: Installments Payments ---\")\n",
    "\n",
    "# --- 1. FEATURE CREATION SPÉCIFIQUE ---\n",
    "\n",
    "# Calcul de l'écart entre la date de paiement prévue et la date de paiement réelle\n",
    "# (Valeur négative = paiement en avance, positive = paiement en retard)\n",
    "df_installments['DAYS_DELAY'] = df_installments['DAYS_ENTRY_PAYMENT'] - df_installments['DAYS_INSTALMENT']\n",
    "\n",
    "# Ratio du montant payé par rapport au montant attendu (si > 1, le client a trop payé)\n",
    "df_installments['PAYMENT_RATIO'] = df_installments['AMT_PAYMENT'] / df_installments['AMT_INSTALMENT']\n",
    "\n",
    "# Difference entre le montant payé et le montant attendu\n",
    "df_installments['PAYMENT_DIFF'] = df_installments['AMT_PAYMENT'] - df_installments['AMT_INSTALMENT']\n",
    "\n",
    "# Flag pour le paiement en retard (> 0 jour de retard)\n",
    "df_installments['LATE_PAYMENT_FLAG'] = (df_installments['DAYS_DELAY'] > 0).astype(np.int8)\n",
    "\n",
    "# --- 2. AGRÉGATION PAR CLIENT (SK_ID_CURR) ---\n",
    "\n",
    "INSTALL_IGNORE_COLS = ['SK_ID_CURR', 'SK_ID_PREV', 'NUM_INSTALMENT_VERSION', 'NUM_INSTALMENT_NUMBER']\n",
    "install_cols = [col for col in df_installments.columns if col not in INSTALL_IGNORE_COLS]\n",
    "\n",
    "# Fonctions d'agrégation pour les colonnes numériques\n",
    "install_agg_funcs = {\n",
    "    'DAYS_DELAY': ['mean', 'min', 'max', 'sum', 'std'],\n",
    "    'PAYMENT_RATIO': ['mean', 'min', 'max', 'var'],\n",
    "    'PAYMENT_DIFF': ['mean', 'min', 'max', 'sum', 'var'],\n",
    "    'LATE_PAYMENT_FLAG': ['sum', 'mean'], # Nombre total et fréquence des retards\n",
    "    'AMT_INSTALMENT': ['mean', 'sum', 'std'],\n",
    "    'AMT_PAYMENT': ['mean', 'sum', 'std'],\n",
    "    'SK_ID_PREV': ['nunique'] # Compter le nombre de prêts précédents associés aux versements\n",
    "}\n",
    "\n",
    "# Agrégation\n",
    "install_grouped = df_installments.groupby('SK_ID_CURR').agg(install_agg_funcs)\n",
    "\n",
    "# Aplatir les noms de colonnes\n",
    "install_grouped.columns = pd.Index([f'INSTAL_{col[0]}_{col[1].upper()}' for col in install_grouped.columns.tolist()])\n",
    "\n",
    "print(f\"Installments Payments aggregation done. Aggregated shape: {install_grouped.shape}\")\n",
    "\n",
    "# --- 3. FUSION DANS LES DATAFRAMES PRINCIPAUX ---\n",
    "\n",
    "# Fusion avec df_train\n",
    "df_train = df_train.merge(install_grouped, how='left', on='SK_ID_CURR')\n",
    "print(f\"Merged installments_payments features into df_train. New shape: {df_train.shape}\")\n",
    "\n",
    "# Fusion avec df_test\n",
    "df_test = df_test.merge(install_grouped, how='left', on='SK_ID_CURR')\n",
    "print(f\"Merged installments_payments features into df_test. New shape: {df_test.shape}\")\n",
    "\n",
    "# Mise à jour des DataFrames\n",
    "dataframes['train'] = df_train\n",
    "dataframes['test'] = df_test\n",
    "\n",
    "print(\"\\nFeature Engineering for Installments Payments completed.\")\n",
    "print(f\"Total columns in df_train: {df_train.shape[1]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ec07a1e",
   "metadata": {},
   "source": [
    "enrichissement des donner 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c70463f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Starting Feature Engineering: POS CASH Balance ---\n",
      "Processing POS_CASH_balance...\n",
      "POS CASH Balance aggregation done. Aggregated shape: (337252, 42)\n",
      "Merged POS_CASH_balance features into df_train. New shape: (307511, 893)\n",
      "Merged POS_CASH_balance features into df_test. New shape: (48744, 892)\n",
      "\n",
      "Feature Engineering for POS CASH Balance completed.\n",
      "Total columns in df_train: 893\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Récupération des DataFrames mis à jour\n",
    "dataframes = globals().get('dataframes') \n",
    "\n",
    "if dataframes is None or 'POS_CASH_balance' not in dataframes:\n",
    "    print(\"Error: DataFrames not loaded or POS_CASH_balance is missing.\")\n",
    "    exit() \n",
    "\n",
    "df_train = dataframes['train']\n",
    "df_test = dataframes['test']\n",
    "df_pos_cash = dataframes['POS_CASH_balance']\n",
    "\n",
    "print(\"\\n--- Starting Feature Engineering: POS CASH Balance ---\")\n",
    "\n",
    "# --- 1. PRÉ-TRAITEMENT ---\n",
    "print(\"Processing POS_CASH_balance...\")\n",
    "\n",
    "# One-Hot Encoding pour le statut du prêt (NAME_CONTRACT_STATUS)\n",
    "df_pos_cash = pd.get_dummies(df_pos_cash, columns=['NAME_CONTRACT_STATUS'], dummy_na=False)\n",
    "\n",
    "# Création d'une colonne indiquant les retards (Status 1 à 5)\n",
    "status_cols = [col for col in df_pos_cash.columns if 'NAME_CONTRACT_STATUS_' in col]\n",
    "if status_cols:\n",
    "    df_pos_cash['LATE_PAYMENT_POS_CASH'] = df_pos_cash[status_cols].sum(axis=1)\n",
    "    df_pos_cash['LATE_PAYMENT_POS_CASH'] = df_pos_cash['LATE_PAYMENT_POS_CASH'].clip(upper=1)\n",
    "else:\n",
    "    df_pos_cash['LATE_PAYMENT_POS_CASH'] = 0  # Aucun retard si la colonne n'existe pas\n",
    "\n",
    "# --- 2. AGRÉGATION PAR CLIENT (SK_ID_CURR) ---\n",
    "POS_CASH_IGNORE_COLS = ['SK_ID_CURR', 'SK_ID_PREV', 'MONTHS_BALANCE']\n",
    "pos_cash_cols = [col for col in df_pos_cash.columns if col not in POS_CASH_IGNORE_COLS]\n",
    "\n",
    "# Fonctions d'agrégation\n",
    "pos_cash_agg_funcs = {\n",
    "    'SK_ID_PREV': ['nunique'],\n",
    "    'MONTHS_BALANCE': ['min', 'max', 'size'],\n",
    "    'CNT_INSTALMENT': ['mean', 'sum', 'min', 'max', 'std'],\n",
    "    'CNT_INSTALMENT_FUTURE': ['mean', 'sum', 'min', 'max', 'std'],\n",
    "    'SK_DPD': ['mean', 'min', 'max', 'sum'],\n",
    "    'SK_DPD_DEF': ['mean', 'min', 'max', 'sum'],\n",
    "    'LATE_PAYMENT_POS_CASH': ['mean', 'sum'],\n",
    "}\n",
    "\n",
    "# Ajout des colonnes OHE existantes\n",
    "for col in status_cols:\n",
    "    pos_cash_agg_funcs[col] = ['mean', 'sum']\n",
    "\n",
    "# Agrégation\n",
    "pos_cash_grouped = df_pos_cash.groupby('SK_ID_CURR').agg(pos_cash_agg_funcs)\n",
    "\n",
    "# Aplatir les noms de colonnes\n",
    "pos_cash_grouped.columns = pd.Index([f'POS_{col[0]}_{col[1].upper()}' for col in pos_cash_grouped.columns.tolist()])\n",
    "\n",
    "print(f\"POS CASH Balance aggregation done. Aggregated shape: {pos_cash_grouped.shape}\")\n",
    "\n",
    "# --- 3. FUSION DANS LES DATAFRAMES PRINCIPAUX ---\n",
    "df_train = df_train.merge(pos_cash_grouped, how='left', on='SK_ID_CURR')\n",
    "print(f\"Merged POS_CASH_balance features into df_train. New shape: {df_train.shape}\")\n",
    "\n",
    "df_test = df_test.merge(pos_cash_grouped, how='left', on='SK_ID_CURR')\n",
    "print(f\"Merged POS_CASH_balance features into df_test. New shape: {df_test.shape}\")\n",
    "\n",
    "# Mise à jour des DataFrames\n",
    "dataframes['train'] = df_train\n",
    "dataframes['test'] = df_test\n",
    "\n",
    "print(\"\\nFeature Engineering for POS CASH Balance completed.\")\n",
    "print(f\"Total columns in df_train: {df_train.shape[1]}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ae12324",
   "metadata": {},
   "source": [
    "enrichissemnt donner 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e025043e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Starting Feature Engineering: Credit Card Balance (FINAL FILE) ---\n",
      "Processing credit_card_balance...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maill\\AppData\\Local\\Temp\\ipykernel_16988\\2183741901.py:33: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df_cc_balance['LIMIT_USE'].replace([np.inf, -np.inf], np.nan, inplace=True)\n",
      "C:\\Users\\maill\\AppData\\Local\\Temp\\ipykernel_16988\\2183741901.py:34: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df_cc_balance['LIMIT_USE'].fillna(0, inplace=True)\n",
      "C:\\Users\\maill\\AppData\\Local\\Temp\\ipykernel_16988\\2183741901.py:38: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df_cc_balance['PAYMENT_DIV_MIN'].replace([np.inf, -np.inf], np.nan, inplace=True)\n",
      "C:\\Users\\maill\\AppData\\Local\\Temp\\ipykernel_16988\\2183741901.py:39: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df_cc_balance['PAYMENT_DIV_MIN'].fillna(0, inplace=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Credit Card Balance aggregation done. Aggregated shape: (103558, 50)\n",
      "Merged credit_card_balance features into df_train. New shape: (307511, 943)\n",
      "Merged credit_card_balance features into df_test. New shape: (48744, 942)\n",
      "\n",
      "Feature Engineering for Credit Card Balance completed.\n",
      "Total columns in df_train: 943\n"
     ]
    }
   ],
   "source": [
    "# Nécessaire pour les opérations de fusion et d'agrégation\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Récupération des DataFrames mis à jour\n",
    "dataframes = globals().get('dataframes') \n",
    "\n",
    "if dataframes is None or 'credit_card_balance' not in dataframes:\n",
    "    print(\"Error: DataFrames not loaded or credit_card_balance is missing.\")\n",
    "    exit() \n",
    "\n",
    "df_train = dataframes['train']\n",
    "df_test = dataframes['test']\n",
    "df_cc_balance = dataframes['credit_card_balance']\n",
    "\n",
    "print(\"\\n--- Starting Feature Engineering: Credit Card Balance (FINAL FILE) ---\")\n",
    "\n",
    "# --- 1. PRÉ-TRAITEMENT ET FEATURE CREATION ---\n",
    "\n",
    "print(\"Processing credit_card_balance...\")\n",
    "\n",
    "# One-Hot Encoding\n",
    "df_cc_balance = pd.get_dummies(df_cc_balance, columns=['NAME_CONTRACT_STATUS'], dummy_na=False)\n",
    "\n",
    "# Remplacer les valeurs infinies (souvent le résultat de divisions par zéro dans les ratios)\n",
    "df_cc_balance = df_cc_balance.replace([np.inf, -np.inf], np.nan)\n",
    "# Imputer les NaN par 0 est souvent une bonne première approche pour ce fichier\n",
    "df_cc_balance.fillna(0, inplace=True) \n",
    "\n",
    "# Création de quelques ratios clés\n",
    "# Ratio d'utilisation du crédit (très prédictif)\n",
    "df_cc_balance['LIMIT_USE'] = df_cc_balance['AMT_BALANCE'] / df_cc_balance['AMT_CREDIT_LIMIT_ACTUAL']\n",
    "df_cc_balance['LIMIT_USE'].replace([np.inf, -np.inf], np.nan, inplace=True)\n",
    "df_cc_balance['LIMIT_USE'].fillna(0, inplace=True)\n",
    "\n",
    "# Ratio Paiement / Paiement minimum (important : si < 1, le client n'a pas respecté le minimum)\n",
    "df_cc_balance['PAYMENT_DIV_MIN'] = df_cc_balance['AMT_PAYMENT_CURRENT'] / df_cc_balance['AMT_INST_MIN_REGULARITY']\n",
    "df_cc_balance['PAYMENT_DIV_MIN'].replace([np.inf, -np.inf], np.nan, inplace=True)\n",
    "df_cc_balance['PAYMENT_DIV_MIN'].fillna(0, inplace=True)\n",
    "\n",
    "# Jours de retard flag\n",
    "df_cc_balance['CC_LATE_PAYMENT'] = (df_cc_balance['SK_DPD'] > 0).astype(np.int8)\n",
    "\n",
    "\n",
    "# --- 2. AGRÉGATION PAR CLIENT (SK_ID_CURR) ---\n",
    "\n",
    "CC_IGNORE_COLS = ['SK_ID_CURR', 'SK_ID_PREV', 'MONTHS_BALANCE']\n",
    "cc_cols = [col for col in df_cc_balance.columns if col not in CC_IGNORE_COLS]\n",
    "\n",
    "# Fonctions d'agrégation\n",
    "cc_agg_funcs = {\n",
    "    'SK_ID_PREV': ['nunique'],\n",
    "    'MONTHS_BALANCE': ['min', 'max', 'size'],\n",
    "    'AMT_BALANCE': ['mean', 'min', 'max', 'sum', 'std'],\n",
    "    'AMT_CREDIT_LIMIT_ACTUAL': ['mean', 'min', 'max'],\n",
    "    'AMT_DRAWINGS_CURRENT': ['mean', 'sum', 'max'],\n",
    "    'AMT_INST_MIN_REGULARITY': ['mean', 'min', 'max', 'sum'],\n",
    "    'AMT_PAYMENT_TOTAL_CURRENT': ['mean', 'sum', 'max', 'std'],\n",
    "    'LIMIT_USE': ['mean', 'min', 'max', 'std'],\n",
    "    'PAYMENT_DIV_MIN': ['mean', 'min', 'max', 'std'],\n",
    "    'CC_LATE_PAYMENT': ['mean', 'sum'],\n",
    "    'SK_DPD': ['mean', 'max', 'sum'],\n",
    "}\n",
    "\n",
    "# Ajout des colonnes OHE\n",
    "for col in df_cc_balance.columns:\n",
    "    if 'NAME_CONTRACT_STATUS_' in col:\n",
    "        cc_agg_funcs[col] = ['mean', 'sum']\n",
    "\n",
    "# Agrégation\n",
    "cc_grouped = df_cc_balance.groupby('SK_ID_CURR').agg(cc_agg_funcs)\n",
    "\n",
    "# Aplatir les noms de colonnes\n",
    "cc_grouped.columns = pd.Index([f'CC_{col[0]}_{col[1].upper()}' for col in cc_grouped.columns.tolist()])\n",
    "\n",
    "print(f\"Credit Card Balance aggregation done. Aggregated shape: {cc_grouped.shape}\")\n",
    "\n",
    "# --- 3. FUSION DANS LES DATAFRAMES PRINCIPAUX ---\n",
    "\n",
    "# Fusion avec df_train\n",
    "df_train = df_train.merge(cc_grouped, how='left', on='SK_ID_CURR')\n",
    "print(f\"Merged credit_card_balance features into df_train. New shape: {df_train.shape}\")\n",
    "\n",
    "# Fusion avec df_test\n",
    "df_test = df_test.merge(cc_grouped, how='left', on='SK_ID_CURR')\n",
    "print(f\"Merged credit_card_balance features into df_test. New shape: {df_test.shape}\")\n",
    "\n",
    "# Mise à jour des DataFrames\n",
    "dataframes['train'] = df_train\n",
    "dataframes['test'] = df_test\n",
    "\n",
    "print(\"\\nFeature Engineering for Credit Card Balance completed.\")\n",
    "print(f\"Total columns in df_train: {df_train.shape[1]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf002a4b",
   "metadata": {},
   "source": [
    "ETAPE 2 TRAITEMNT ML FLOW "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a3034916",
   "metadata": {},
   "outputs": [],
   "source": [
    "import mlflow\n",
    "import mlflow.lightgbm\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import roc_auc_score\n",
    "import lightgbm as lgb\n",
    "\n",
    "# Features et target\n",
    "X = df_train.drop(columns=['TARGET', 'SK_ID_CURR'])\n",
    "y = df_train['TARGET']\n",
    "\n",
    "# Split train/validation\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, stratify=y\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "e645aed3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 50 rounds\n",
      "[100]\tvalid_0's auc: 0.75657\tvalid_0's binary_logloss: 0.246512\n",
      "[200]\tvalid_0's auc: 0.758908\tvalid_0's binary_logloss: 0.245595\n",
      "Early stopping, best iteration is:\n",
      "[190]\tvalid_0's auc: 0.758976\tvalid_0's binary_logloss: 0.245578\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/12/13 16:21:42 WARNING mlflow.models.model: `artifact_path` is deprecated. Please use `name` instead.\n",
      "2025/12/13 16:22:06 WARNING mlflow.models.model: `artifact_path` is deprecated. Please use `name` instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation AUC: 0.7590\n",
      "MLflow run completed and model logged successfully!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import mlflow\n",
    "import mlflow.lightgbm\n",
    "from lightgbm import LGBMClassifier, early_stopping, log_evaluation\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import roc_auc_score\n",
    "import numpy as np\n",
    "\n",
    "# --- 1. Chargement des données ---\n",
    "data_path = \"C:/Users/maill/OneDrive/Bureau/majeur_ia/dataenginnering/projet/home-credit-default-risk/application_train.csv\"\n",
    "df_train = pd.read_csv(data_path)\n",
    "\n",
    "# Features / cible\n",
    "X = df_train.drop(columns=['SK_ID_CURR', 'TARGET'])\n",
    "y = df_train['TARGET']\n",
    "\n",
    "# Identifier les colonnes numériques et catégorielles\n",
    "num_cols = X.select_dtypes(include=['int64', 'float64']).columns\n",
    "cat_cols = X.select_dtypes(include=['object']).columns\n",
    "\n",
    "# Split train / validation\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "# Conversion types pour LightGBM\n",
    "X_train[num_cols] = X_train[num_cols].astype(np.float32)\n",
    "X_val[num_cols] = X_val[num_cols].astype(np.float32)\n",
    "\n",
    "# Conversion colonnes catégorielles en \"category\"\n",
    "X_train[cat_cols] = X_train[cat_cols].astype(\"category\")\n",
    "X_val[cat_cols] = X_val[cat_cols].astype(\"category\")\n",
    "\n",
    "y_train = y_train.astype(np.int8)\n",
    "y_val = y_val.astype(np.int8)\n",
    "\n",
    "# --- 2. Configurer MLflow ---\n",
    "mlflow.set_tracking_uri(\"file:///C:/Users/maill/OneDrive/Bureau/mlruns\")\n",
    "mlflow.set_experiment(\"home_credit_default_risk\")\n",
    "\n",
    "# --- 3. Entraînement LightGBM avec MLflow ---\n",
    "with mlflow.start_run(run_name=\"lightgbm_baseline\"):\n",
    "    # Définition du modèle\n",
    "    model = LGBMClassifier(\n",
    "        objective='binary',\n",
    "        boosting_type='gbdt',\n",
    "        learning_rate=0.05,\n",
    "        num_leaves=31,\n",
    "        max_depth=-1,\n",
    "        n_estimators=1000,\n",
    "        verbosity=-1,\n",
    "        random_state=42\n",
    "    )\n",
    "\n",
    "    # Fit avec early stopping et logs toutes les 100 itérations\n",
    "    model.fit(\n",
    "        X_train, y_train,\n",
    "        eval_set=[(X_val, y_val)],\n",
    "        eval_metric='auc',\n",
    "        callbacks=[early_stopping(stopping_rounds=50), log_evaluation(period=100)]\n",
    "    )\n",
    "\n",
    "    # Prédictions et AUC\n",
    "    y_pred = model.predict_proba(X_val)[:, 1]\n",
    "    auc_score = roc_auc_score(y_val, y_pred)\n",
    "    print(f\"Validation AUC: {auc_score:.4f}\")\n",
    "\n",
    "    # Logging manuel hyperparamètres et métrique\n",
    "    mlflow.log_params(model.get_params())\n",
    "    mlflow.log_metric(\"val_auc\", auc_score)\n",
    "\n",
    "    # Log du modèle LightGBM (booster_)\n",
    "    mlflow.lightgbm.log_model(model.booster_, artifact_path=\"model\")\n",
    "\n",
    "    print(\"MLflow run completed and model logged successfully!\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "673d3f7c",
   "metadata": {},
   "source": [
    "PARTIE 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "7c958702",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-12-13 16:29:35,297] A new study created in memory with name: LGBM_Optimization_Optuna\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Starting 50 optimization trials...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/50 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[273]\tvalid_0's auc: 0.761202\tvalid_0's binary_logloss: 0.244932\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/12/13 16:30:01 WARNING mlflow.models.model: `artifact_path` is deprecated. Please use `name` instead.\n",
      "2025/12/13 16:30:09 WARNING mlflow.models.model: `artifact_path` is deprecated. Please use `name` instead.\n",
      "c:\\Users\\maill\\OneDrive\\Bureau\\majeur_ia\\dataenginnering\\projet\\.venv\\lib\\site-packages\\mlflow\\tracking\\_model_registry\\utils.py:215: FutureWarning: The filesystem model registry backend (e.g., './mlruns') will be deprecated in February 2026. Consider transitioning to a database backend (e.g., 'sqlite:///mlflow.db') to take advantage of the latest MLflow features. See https://github.com/mlflow/mlflow/issues/18534 for more details and migration guidance.\n",
      "  return FileStore(store_uri)\n",
      "Successfully registered model 'HomeCredit_LGBM_Optimized'.\n",
      "Created version '1' of model 'HomeCredit_LGBM_Optimized'.\n",
      "Best trial: 0. Best value: 0.761202:   2%|▏         | 1/50 [00:37<30:33, 37.42s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-12-13 16:30:12,717] Trial 0 finished with value: 0.7612021352766262 and parameters: {'learning_rate': 0.0686366684731388, 'num_leaves': 74, 'max_depth': 5, 'min_child_samples': 45, 'subsample': 0.9451176882644856, 'colsample_bytree': 0.6950097958247732, 'reg_alpha': 0.010544887165465613, 'reg_lambda': 0.003193184470047511}. Best is trial 0 with value: 0.7612021352766262.\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[969]\tvalid_0's auc: 0.761335\tvalid_0's binary_logloss: 0.244817\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/12/13 16:30:46 WARNING mlflow.models.model: `artifact_path` is deprecated. Please use `name` instead.\n",
      "2025/12/13 16:30:54 WARNING mlflow.models.model: `artifact_path` is deprecated. Please use `name` instead.\n",
      "Registered model 'HomeCredit_LGBM_Optimized' already exists. Creating a new version of this model...\n",
      "Created version '2' of model 'HomeCredit_LGBM_Optimized'.\n",
      "Best trial: 1. Best value: 0.761335:   4%|▍         | 2/50 [01:23<33:51, 42.33s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-12-13 16:30:58,475] Trial 1 finished with value: 0.7613351759390266 and parameters: {'learning_rate': 0.043521511072668516, 'num_leaves': 89, 'max_depth': 3, 'min_child_samples': 55, 'subsample': 0.9428355459739732, 'colsample_bytree': 0.8348599127686024, 'reg_alpha': 2.1264075957530384, 'reg_lambda': 2.717094731430946}. Best is trial 1 with value: 0.7613351759390266.\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[541]\tvalid_0's auc: 0.761422\tvalid_0's binary_logloss: 0.244769\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/12/13 16:31:27 WARNING mlflow.models.model: `artifact_path` is deprecated. Please use `name` instead.\n",
      "2025/12/13 16:31:35 WARNING mlflow.models.model: `artifact_path` is deprecated. Please use `name` instead.\n",
      "Registered model 'HomeCredit_LGBM_Optimized' already exists. Creating a new version of this model...\n",
      "Created version '3' of model 'HomeCredit_LGBM_Optimized'.\n",
      "Best trial: 2. Best value: 0.761422:   6%|▌         | 3/50 [02:03<32:34, 41.59s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-12-13 16:31:39,195] Trial 2 finished with value: 0.7614221728333789 and parameters: {'learning_rate': 0.09568614915227072, 'num_leaves': 33, 'max_depth': 3, 'min_child_samples': 82, 'subsample': 0.996852935670556, 'colsample_bytree': 0.9999538384549915, 'reg_alpha': 4.529034056419769e-05, 'reg_lambda': 1.3491337131447425e-07}. Best is trial 2 with value: 0.7614221728333789.\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[438]\tvalid_0's auc: 0.760317\tvalid_0's binary_logloss: 0.245095\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/12/13 16:32:15 WARNING mlflow.models.model: `artifact_path` is deprecated. Please use `name` instead.\n",
      "2025/12/13 16:32:23 WARNING mlflow.models.model: `artifact_path` is deprecated. Please use `name` instead.\n",
      "Registered model 'HomeCredit_LGBM_Optimized' already exists. Creating a new version of this model...\n",
      "Created version '4' of model 'HomeCredit_LGBM_Optimized'.\n",
      "Best trial: 2. Best value: 0.761422:   8%|▊         | 4/50 [02:52<33:56, 44.26s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-12-13 16:32:27,548] Trial 3 finished with value: 0.7603174465768496 and parameters: {'learning_rate': 0.02059809995365799, 'num_leaves': 127, 'max_depth': 9, 'min_child_samples': 47, 'subsample': 0.6237727549362793, 'colsample_bytree': 0.641129360204188, 'reg_alpha': 0.28733274655242, 'reg_lambda': 0.0030085559688135598}. Best is trial 2 with value: 0.7614221728333789.\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[518]\tvalid_0's auc: 0.761413\tvalid_0's binary_logloss: 0.244777\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/12/13 16:32:56 WARNING mlflow.models.model: `artifact_path` is deprecated. Please use `name` instead.\n",
      "2025/12/13 16:33:04 WARNING mlflow.models.model: `artifact_path` is deprecated. Please use `name` instead.\n",
      "Registered model 'HomeCredit_LGBM_Optimized' already exists. Creating a new version of this model...\n",
      "Created version '5' of model 'HomeCredit_LGBM_Optimized'.\n",
      "Best trial: 2. Best value: 0.761422:  10%|█         | 5/50 [03:32<32:07, 42.83s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-12-13 16:33:07,847] Trial 4 finished with value: 0.7614131991968828 and parameters: {'learning_rate': 0.07498813548376373, 'num_leaves': 50, 'max_depth': 3, 'min_child_samples': 37, 'subsample': 0.9732981505855366, 'colsample_bytree': 0.942999532462288, 'reg_alpha': 7.300707743788206e-05, 'reg_lambda': 0.021511945818516495}. Best is trial 2 with value: 0.7614221728333789.\n",
      "Training until validation scores don't improve for 50 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 2. Best value: 0.761422:  12%|█▏        | 6/50 [03:59<27:23, 37.35s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-12-13 16:33:34,558] Trial 5 pruned. Trial was pruned at iteration 239.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 2. Best value: 0.761422:  14%|█▍        | 7/50 [04:20<22:55, 31.99s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-12-13 16:33:55,508] Trial 6 pruned. Trial was pruned at iteration 0.\n",
      "Training until validation scores don't improve for 50 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 2. Best value: 0.761422:  16%|█▌        | 8/50 [04:41<20:00, 28.59s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-12-13 16:34:16,813] Trial 7 pruned. Trial was pruned at iteration 26.\n",
      "Training until validation scores don't improve for 50 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 2. Best value: 0.761422:  18%|█▊        | 9/50 [05:02<17:58, 26.30s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-12-13 16:34:38,079] Trial 8 pruned. Trial was pruned at iteration 28.\n",
      "Training until validation scores don't improve for 50 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 2. Best value: 0.761422:  20%|██        | 10/50 [05:23<16:25, 24.64s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-12-13 16:34:58,998] Trial 9 pruned. Trial was pruned at iteration 19.\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[175]\tvalid_0's auc: 0.759992\tvalid_0's binary_logloss: 0.24528\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/12/13 16:35:24 WARNING mlflow.models.model: `artifact_path` is deprecated. Please use `name` instead.\n",
      "Best trial: 2. Best value: 0.761422:  22%|██▏       | 11/50 [05:56<17:37, 27.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-12-13 16:35:31,722] Trial 10 finished with value: 0.7599915030100155 and parameters: {'learning_rate': 0.0997946467919018, 'num_leaves': 16, 'max_depth': 5, 'min_child_samples': 88, 'subsample': 0.6736297378098522, 'colsample_bytree': 0.9951266654957489, 'reg_alpha': 0.0005113576626955219, 'reg_lambda': 1.3909840694277171e-06}. Best is trial 2 with value: 0.7614221728333789.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 2. Best value: 0.761422:  24%|██▍       | 12/50 [06:17<15:54, 25.13s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-12-13 16:35:52,315] Trial 11 pruned. Trial was pruned at iteration 0.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 2. Best value: 0.761422:  26%|██▌       | 13/50 [06:37<14:40, 23.80s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 50 rounds\n",
      "[I 2025-12-13 16:36:13,052] Trial 12 pruned. Trial was pruned at iteration 7.\n",
      "Training until validation scores don't improve for 50 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 2. Best value: 0.761422:  28%|██▊       | 14/50 [06:58<13:44, 22.91s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-12-13 16:36:33,897] Trial 13 pruned. Trial was pruned at iteration 16.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 2. Best value: 0.761422:  30%|███       | 15/50 [07:19<12:56, 22.17s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-12-13 16:36:54,369] Trial 14 pruned. Trial was pruned at iteration 0.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 2. Best value: 0.761422:  32%|███▏      | 16/50 [07:39<12:15, 21.65s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 50 rounds\n",
      "[I 2025-12-13 16:37:14,789] Trial 15 pruned. Trial was pruned at iteration 3.\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[216]\tvalid_0's auc: 0.759686\tvalid_0's binary_logloss: 0.245377\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/12/13 16:37:42 WARNING mlflow.models.model: `artifact_path` is deprecated. Please use `name` instead.\n",
      "Best trial: 2. Best value: 0.761422:  34%|███▍      | 17/50 [08:16<14:30, 26.38s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-12-13 16:37:52,177] Trial 16 finished with value: 0.7596859433844403 and parameters: {'learning_rate': 0.07290090191214572, 'num_leaves': 58, 'max_depth': 6, 'min_child_samples': 21, 'subsample': 0.8238474475612387, 'colsample_bytree': 0.9331951636673116, 'reg_alpha': 1.7783352777032117e-05, 'reg_lambda': 0.006523072719765516}. Best is trial 2 with value: 0.7614221728333789.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 2. Best value: 0.761422:  36%|███▌      | 18/50 [08:39<13:29, 25.30s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 50 rounds\n",
      "[I 2025-12-13 16:38:14,964] Trial 17 pruned. Trial was pruned at iteration 7.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 2. Best value: 0.761422:  38%|███▊      | 19/50 [09:00<12:21, 23.91s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 50 rounds\n",
      "[I 2025-12-13 16:38:35,654] Trial 18 pruned. Trial was pruned at iteration 3.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 2. Best value: 0.761422:  40%|████      | 20/50 [09:22<11:44, 23.48s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-12-13 16:38:58,111] Trial 19 pruned. Trial was pruned at iteration 0.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 2. Best value: 0.761422:  42%|████▏     | 21/50 [09:44<11:09, 23.08s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 50 rounds\n",
      "[I 2025-12-13 16:39:20,254] Trial 20 pruned. Trial was pruned at iteration 1.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 2. Best value: 0.761422:  44%|████▍     | 22/50 [10:05<10:26, 22.38s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-12-13 16:39:41,011] Trial 21 pruned. Trial was pruned at iteration 0.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 2. Best value: 0.761422:  46%|████▌     | 23/50 [10:26<09:51, 21.92s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-12-13 16:40:01,842] Trial 22 pruned. Trial was pruned at iteration 0.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 2. Best value: 0.761422:  48%|████▊     | 24/50 [10:46<09:18, 21.48s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-12-13 16:40:22,291] Trial 23 pruned. Trial was pruned at iteration 0.\n",
      "Training until validation scores don't improve for 50 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 2. Best value: 0.761422:  50%|█████     | 25/50 [11:07<08:52, 21.31s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-12-13 16:40:43,221] Trial 24 pruned. Trial was pruned at iteration 12.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 2. Best value: 0.761422:  52%|█████▏    | 26/50 [11:28<08:25, 21.06s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-12-13 16:41:03,702] Trial 25 pruned. Trial was pruned at iteration 0.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 2. Best value: 0.761422:  54%|█████▍    | 27/50 [11:49<08:01, 20.94s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 50 rounds\n",
      "[I 2025-12-13 16:41:24,360] Trial 26 pruned. Trial was pruned at iteration 12.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 2. Best value: 0.761422:  56%|█████▌    | 28/50 [12:09<07:36, 20.76s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-12-13 16:41:44,712] Trial 27 pruned. Trial was pruned at iteration 0.\n",
      "Training until validation scores don't improve for 50 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 2. Best value: 0.761422:  58%|█████▊    | 29/50 [12:30<07:15, 20.73s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-12-13 16:42:05,375] Trial 28 pruned. Trial was pruned at iteration 11.\n",
      "Training until validation scores don't improve for 50 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 2. Best value: 0.761422:  60%|██████    | 30/50 [12:50<06:53, 20.69s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-12-13 16:42:25,969] Trial 29 pruned. Trial was pruned at iteration 15.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 2. Best value: 0.761422:  62%|██████▏   | 31/50 [13:10<06:30, 20.54s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-12-13 16:42:46,138] Trial 30 pruned. Trial was pruned at iteration 0.\n",
      "Training until validation scores don't improve for 50 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 2. Best value: 0.761422:  64%|██████▍   | 32/50 [13:31<06:09, 20.54s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-12-13 16:43:06,677] Trial 31 pruned. Trial was pruned at iteration 15.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 2. Best value: 0.761422:  66%|██████▌   | 33/50 [13:51<05:47, 20.44s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-12-13 16:43:26,903] Trial 32 pruned. Trial was pruned at iteration 0.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 2. Best value: 0.761422:  68%|██████▊   | 34/50 [14:11<05:26, 20.40s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-12-13 16:43:47,215] Trial 33 pruned. Trial was pruned at iteration 0.\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[218]\tvalid_0's auc: 0.760918\tvalid_0's binary_logloss: 0.245231\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/12/13 16:44:15 WARNING mlflow.models.model: `artifact_path` is deprecated. Please use `name` instead.\n",
      "2025/12/13 16:44:38 WARNING mlflow.models.model: `artifact_path` is deprecated. Please use `name` instead.\n",
      "Registered model 'HomeCredit_LGBM_Optimized' already exists. Creating a new version of this model...\n",
      "Created version '6' of model 'HomeCredit_LGBM_Optimized'.\n",
      "Best trial: 2. Best value: 0.761422:  70%|███████   | 35/50 [15:07<07:44, 30.99s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-12-13 16:44:42,908] Trial 34 finished with value: 0.7609181814888235 and parameters: {'learning_rate': 0.059675697488993644, 'num_leaves': 93, 'max_depth': 8, 'min_child_samples': 58, 'subsample': 0.9506751811770928, 'colsample_bytree': 0.7292348899363165, 'reg_alpha': 0.030221647727149862, 'reg_lambda': 0.08815481107636274}. Best is trial 2 with value: 0.7614221728333789.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 2. Best value: 0.761422:  72%|███████▏  | 36/50 [15:27<06:28, 27.78s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-12-13 16:45:03,181] Trial 35 pruned. Trial was pruned at iteration 0.\n",
      "Training until validation scores don't improve for 50 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 2. Best value: 0.761422:  74%|███████▍  | 37/50 [15:48<05:32, 25.58s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-12-13 16:45:23,623] Trial 36 pruned. Trial was pruned at iteration 12.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 2. Best value: 0.761422:  76%|███████▌  | 38/50 [16:08<04:47, 23.95s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-12-13 16:45:43,787] Trial 37 pruned. Trial was pruned at iteration 0.\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[196]\tvalid_0's auc: 0.760031\tvalid_0's binary_logloss: 0.245274\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/12/13 16:46:10 WARNING mlflow.models.model: `artifact_path` is deprecated. Please use `name` instead.\n",
      "2025/12/13 16:46:18 WARNING mlflow.models.model: `artifact_path` is deprecated. Please use `name` instead.\n",
      "Registered model 'HomeCredit_LGBM_Optimized' already exists. Creating a new version of this model...\n",
      "Created version '7' of model 'HomeCredit_LGBM_Optimized'.\n",
      "Best trial: 2. Best value: 0.761422:  78%|███████▊  | 39/50 [16:46<05:09, 28.15s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-12-13 16:46:21,732] Trial 38 finished with value: 0.7600314551073974 and parameters: {'learning_rate': 0.07108442853103897, 'num_leaves': 45, 'max_depth': 9, 'min_child_samples': 53, 'subsample': 0.9996223254719888, 'colsample_bytree': 0.9769518139401069, 'reg_alpha': 0.0014320927186858296, 'reg_lambda': 0.0007394330177547064}. Best is trial 2 with value: 0.7614221728333789.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 2. Best value: 0.761422:  80%|████████  | 40/50 [17:06<04:17, 25.76s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-12-13 16:46:41,924] Trial 39 pruned. Trial was pruned at iteration 0.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 2. Best value: 0.761422:  82%|████████▏ | 41/50 [17:26<03:36, 24.08s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-12-13 16:47:02,066] Trial 40 pruned. Trial was pruned at iteration 0.\n",
      "Training until validation scores don't improve for 50 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 2. Best value: 0.761422:  84%|████████▍ | 42/50 [17:49<03:08, 23.62s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-12-13 16:47:24,633] Trial 41 pruned. Trial was pruned at iteration 97.\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[126]\tvalid_0's auc: 0.759776\tvalid_0's binary_logloss: 0.245287\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/12/13 16:47:50 WARNING mlflow.models.model: `artifact_path` is deprecated. Please use `name` instead.\n",
      "Best trial: 2. Best value: 0.761422:  86%|████████▌ | 43/50 [18:22<03:05, 26.52s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-12-13 16:47:57,915] Trial 42 finished with value: 0.7597764064750256 and parameters: {'learning_rate': 0.08480913778555102, 'num_leaves': 88, 'max_depth': 8, 'min_child_samples': 50, 'subsample': 0.9765139433979347, 'colsample_bytree': 0.6254646170540221, 'reg_alpha': 0.020564663022969186, 'reg_lambda': 0.15987670128162923}. Best is trial 2 with value: 0.7614221728333789.\n",
      "Training until validation scores don't improve for 50 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 2. Best value: 0.761422:  88%|████████▊ | 44/50 [18:46<02:34, 25.71s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-12-13 16:48:21,729] Trial 43 pruned. Trial was pruned at iteration 123.\n",
      "Training until validation scores don't improve for 50 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 2. Best value: 0.761422:  90%|█████████ | 45/50 [19:08<02:03, 24.68s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-12-13 16:48:44,010] Trial 44 pruned. Trial was pruned at iteration 46.\n",
      "Training until validation scores don't improve for 50 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 2. Best value: 0.761422:  92%|█████████▏| 46/50 [19:29<01:34, 23.64s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-12-13 16:49:05,205] Trial 45 pruned. Trial was pruned at iteration 11.\n",
      "Training until validation scores don't improve for 50 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 2. Best value: 0.761422:  94%|█████████▍| 47/50 [19:53<01:10, 23.48s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-12-13 16:49:28,333] Trial 46 pruned. Trial was pruned at iteration 105.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 2. Best value: 0.761422:  96%|█████████▌| 48/50 [20:13<00:45, 22.69s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-12-13 16:49:49,186] Trial 47 pruned. Trial was pruned at iteration 0.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 2. Best value: 0.761422:  98%|█████████▊| 49/50 [20:35<00:22, 22.26s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 50 rounds\n",
      "[I 2025-12-13 16:50:10,430] Trial 48 pruned. Trial was pruned at iteration 6.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 2. Best value: 0.761422: 100%|██████████| 50/50 [20:57<00:00, 25.14s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-12-13 16:50:32,406] Trial 49 pruned. Trial was pruned at iteration 0.\n",
      "\n",
      "--- Optimization Complete ---\n",
      "Best AUC found: 0.7614\n",
      "Best parameters: {'learning_rate': 0.09568614915227072, 'num_leaves': 33, 'max_depth': 3, 'min_child_samples': 82, 'subsample': 0.996852935670556, 'colsample_bytree': 0.9999538384549915, 'reg_alpha': 4.529034056419769e-05, 'reg_lambda': 1.3491337131447425e-07}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import optuna\n",
    "from optuna.integration import LightGBMPruningCallback\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import roc_auc_score\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import mlflow\n",
    "import mlflow.lightgbm\n",
    "from lightgbm import LGBMClassifier, early_stopping, log_evaluation\n",
    "\n",
    "# --- 1. RE-CHARGEMENT ET PRÉPARATION DES DONNÉES (Pour être autonome) ---\n",
    "# Vous avez déjà fait ce chargement, mais on le garde ici si le notebook est relancé\n",
    "data_path = \"C:/Users/maill/OneDrive/Bureau/majeur_ia/dataenginnering/projet/home-credit-default-risk/application_train.csv\"\n",
    "df_train = pd.read_csv(data_path)\n",
    "X = df_train.drop(columns=['SK_ID_CURR', 'TARGET'])\n",
    "y = df_train['TARGET']\n",
    "\n",
    "num_cols = X.select_dtypes(include=['int64', 'float64']).columns\n",
    "cat_cols = X.select_dtypes(include=['object']).columns\n",
    "\n",
    "# Split train / validation\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "# Conversion types pour LightGBM\n",
    "X_train[num_cols] = X_train[num_cols].astype(np.float32)\n",
    "X_val[num_cols] = X_val[num_cols].astype(np.float32)\n",
    "X_train[cat_cols] = X_train[cat_cols].astype(\"category\")\n",
    "X_val[cat_cols] = X_val[cat_cols].astype(\"category\")\n",
    "y_train = y_train.astype(np.int8)\n",
    "y_val = y_val.astype(np.int8)\n",
    "\n",
    "\n",
    "# --- 2. CONFIGURER MLFLOW ---\n",
    "# On réutilise votre configuration MLflow\n",
    "mlflow.set_tracking_uri(\"file:///C:/Users/maill/OneDrive/Bureau/mlruns\")\n",
    "mlflow.set_experiment(\"home_credit_default_risk\")\n",
    "\n",
    "\n",
    "# --- 3. FONCTION OBJECTIF OPTUNA (avec Nested MLflow Run) ---\n",
    "\n",
    "def objective(trial):\n",
    "    \"\"\"\n",
    "    Fonction objectif pour Optuna, trace les résultats dans une run MLflow imbriquée.\n",
    "    \"\"\"\n",
    "    # 1. Définition de l'espace de recherche\n",
    "    param = {\n",
    "        'objective': 'binary',\n",
    "        'boosting_type': 'gbdt',\n",
    "        'n_estimators': 1000, \n",
    "        'learning_rate': trial.suggest_float('learning_rate', 0.005, 0.1, log=True),\n",
    "        'num_leaves': trial.suggest_int('num_leaves', 16, 128),\n",
    "        'max_depth': trial.suggest_int('max_depth', 3, 10),\n",
    "        'min_child_samples': trial.suggest_int('min_child_samples', 20, 100),\n",
    "        'subsample': trial.suggest_float('subsample', 0.6, 1.0),\n",
    "        'colsample_bytree': trial.suggest_float('colsample_bytree', 0.6, 1.0),\n",
    "        'reg_alpha': trial.suggest_float('reg_alpha', 1e-8, 10.0, log=True),\n",
    "        'reg_lambda': trial.suggest_float('reg_lambda', 1e-8, 10.0, log=True),\n",
    "        'random_state': 42,\n",
    "        'n_jobs': -1,\n",
    "        'verbosity': -1,\n",
    "    }\n",
    "\n",
    "    # 2. Démarrer la run MLflow imbriquée\n",
    "    # Le paramètre 'nested=True' permet d'enregistrer cet essai sous la run principale de l'étude\n",
    "    with mlflow.start_run(run_name=f\"trial_{trial.number}\", nested=True):\n",
    "        \n",
    "        # Loguer les paramètres testés\n",
    "        mlflow.log_params(param)\n",
    "        \n",
    "        # 3. Entraînement du modèle\n",
    "        model = LGBMClassifier(**param)\n",
    "\n",
    "        # Callback Optuna pour l'élagage (pruning) intelligent\n",
    "        pruning_callback = LightGBMPruningCallback(trial, 'auc', valid_name='valid_0')\n",
    "\n",
    "        model.fit(\n",
    "            X_train, y_train,\n",
    "            eval_set=[(X_val, y_val)],\n",
    "            eval_metric='auc',\n",
    "            callbacks=[early_stopping(stopping_rounds=50, verbose=-1), pruning_callback]\n",
    "        )\n",
    "\n",
    "        # 4. Évaluation et Log\n",
    "        y_pred = model.predict_proba(X_val)[:, 1]\n",
    "        auc_score = roc_auc_score(y_val, y_pred)\n",
    "        \n",
    "        mlflow.log_metric(\"val_auc\", auc_score)\n",
    "        \n",
    "        # Log du modèle si c'est le meilleur essai de l'étude (facultatif mais utile)\n",
    "        # On ne logue que si l'AUC est significativement meilleure que la baseline (0.7590)\n",
    "        if auc_score > 0.7600:\n",
    "             mlflow.lightgbm.log_model(\n",
    "                 model.booster_, \n",
    "                 artifact_path=f\"model_trial_{trial.number}\",\n",
    "                 registered_model_name=\"HomeCredit_LGBM_Optimized\"\n",
    "             )\n",
    "        \n",
    "        # Retourner la métrique à Optuna\n",
    "        return auc_score\n",
    "\n",
    "# --- 4. EXÉCUTION DE L'ÉTUDE OPTUNA (Main MLflow Run) ---\n",
    "\n",
    "N_TRIALS = 50 # Nombre d'essais (augmentez si vous avez plus de temps)\n",
    "STUDY_NAME = \"LGBM_Optimization_Optuna\"\n",
    "\n",
    "# Démarrer la run principale pour l'étude entière\n",
    "with mlflow.start_run(run_name=STUDY_NAME) as study_run:\n",
    "    \n",
    "    # Tags pour l'étude complète\n",
    "    mlflow.set_tag(\"Optimization_Tool\", \"Optuna\")\n",
    "    mlflow.set_tag(\"Optimization_Phase\", \"4.2_Hyperparameter_Tuning\")\n",
    "    mlflow.log_param(\"N_TRIALS\", N_TRIALS)\n",
    "    mlflow.log_param(\"Validation_Strategy\", \"Holdout_Split_20pct\")\n",
    "    \n",
    "    # Créer le study Optuna\n",
    "    study = optuna.create_study(direction='maximize', study_name=STUDY_NAME)\n",
    "    \n",
    "    print(f\"\\nStarting {N_TRIALS} optimization trials...\")\n",
    "    study.optimize(objective, n_trials=N_TRIALS, show_progress_bar=True)\n",
    "\n",
    "    # Récupération et log des meilleurs résultats\n",
    "    best_params = study.best_params\n",
    "    best_value = study.best_value\n",
    "    \n",
    "    # Loguer les résultats finaux dans la main run\n",
    "    mlflow.log_metric(\"best_auc_found\", best_value)\n",
    "    mlflow.log_params({f\"final_{k}\": v for k, v in best_params.items()})\n",
    "\n",
    "    print(\"\\n--- Optimization Complete ---\")\n",
    "    print(f\"Best AUC found: {best_value:.4f}\")\n",
    "    print(f\"Best parameters: {best_params}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7a66f7f",
   "metadata": {},
   "source": [
    "PARTIE 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "fb3c14b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Starting Final Model Training (Partie 4 / Étape 4.3) ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/12/13 17:11:09 WARNING mlflow.models.model: `artifact_path` is deprecated. Please use `name` instead.\n",
      "2025/12/13 17:11:28 WARNING mlflow.models.model: `artifact_path` is deprecated. Please use `name` instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Submission file created: submission_optimized_auc_0.7614_20251213_1711.csv\n",
      "\n",
      "--- Final Model Training and Submission Completed ---\n",
      "Votre fichier de soumission est prêt à être envoyé à Kaggle !\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Successfully registered model 'HomeCredit_LGBM_FINAL'.\n",
      "Created version '1' of model 'HomeCredit_LGBM_FINAL'.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import mlflow\n",
    "import mlflow.lightgbm\n",
    "from lightgbm import LGBMClassifier\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "# --- 1. CONFIGURATION ET RÉCUPÉRATION DES DONNÉES ---\n",
    "mlflow.set_tracking_uri(\"file:///C:/Users/maill/OneDrive/Bureau/mlruns\")\n",
    "mlflow.set_experiment(\"home_credit_default_risk\")\n",
    "\n",
    "# Chemin des données (à ajuster si besoin)\n",
    "train_path = \"C:/Users/maill/OneDrive/Bureau/majeur_ia/dataenginnering/projet/home-credit-default-risk/application_train.csv\"\n",
    "test_path = \"C:/Users/maill/OneDrive/Bureau/majeur_ia/dataenginnering/projet/home-credit-default-risk/application_test.csv\"\n",
    "sample_submission_path = \"C:/Users/maill/OneDrive/Bureau/majeur_ia/dataenginnering/projet/home-credit-default-risk/sample_submission.csv\"\n",
    "\n",
    "# Chargement des données\n",
    "df_train = pd.read_csv(train_path)\n",
    "df_test = pd.read_csv(test_path)\n",
    "submission = pd.read_csv(sample_submission_path)\n",
    "\n",
    "# Préparation (doit être la même que pour l'optimisation)\n",
    "X_train_full = df_train.drop(columns=['SK_ID_CURR', 'TARGET'])\n",
    "y_train_full = df_train['TARGET']\n",
    "X_test = df_test.drop(columns=['SK_ID_CURR'])\n",
    "\n",
    "# Identifier les colonnes et types\n",
    "num_cols = X_train_full.select_dtypes(include=['int64', 'float64']).columns\n",
    "cat_cols = X_train_full.select_dtypes(include=['object']).columns\n",
    "\n",
    "# Appliquer la même transformation de types pour LightGBM\n",
    "for df in [X_train_full, X_test]:\n",
    "    df[num_cols] = df[num_cols].astype(np.float32)\n",
    "    for col in cat_cols:\n",
    "        # Gère les catégories manquantes dans le test set\n",
    "        if col in df.columns:\n",
    "            df[col] = df[col].astype(\"category\")\n",
    "\n",
    "y_train_full = y_train_full.astype(np.int8)\n",
    "\n",
    "# --- 2. RÉCUPÉRATION DES MEILLEURS PARAMÈTRES OPTUNA ---\n",
    "\n",
    "# Nous utilisons ici les meilleurs paramètres que vous avez trouvés\n",
    "BEST_PARAMS = {\n",
    "    'learning_rate': 0.09568614915227072, \n",
    "    'num_leaves': 33, \n",
    "    'max_depth': 3, \n",
    "    'min_child_samples': 82, \n",
    "    'subsample': 0.996852935670556, \n",
    "    'colsample_bytree': 0.9999538384549915, \n",
    "    'reg_alpha': 4.529034056419769e-05, \n",
    "    'reg_lambda': 1.3491337131447425e-07,\n",
    "    # Paramètres additionnels LightGBM\n",
    "    'objective': 'binary',\n",
    "    'boosting_type': 'gbdt',\n",
    "    'n_estimators': 1000, # Laisser élevé pour que l'early stopping fonctionne\n",
    "    'random_state': 42,\n",
    "    'n_jobs': -1,\n",
    "    'verbosity': -1,\n",
    "}\n",
    "\n",
    "# --- 3. ENTRAÎNEMENT FINAL AVEC MLflow ---\n",
    "print(\"--- Starting Final Model Training (Partie 4 / Étape 4.3) ---\")\n",
    "\n",
    "with mlflow.start_run(run_name=\"final_optimized_model\"):\n",
    "    \n",
    "    # Ajout de tags pour identifier cette run\n",
    "    mlflow.set_tag(\"Model_Phase\", \"4.3_Final_Training\")\n",
    "    mlflow.set_tag(\"Optimization_Source\", \"Optuna_Trial_2\")\n",
    "    mlflow.log_param(\"Train_Data_Size\", len(X_train_full))\n",
    "    \n",
    "    # Initialisation du modèle avec les meilleurs paramètres\n",
    "    final_model = LGBMClassifier(**BEST_PARAMS)\n",
    "    \n",
    "    # Entraînement sur la totalité des données d'entraînement (sans validation split ici)\n",
    "    # Dans un vrai cas, on ferait du K-Fold ici, mais pour la simplicité, on fait un fit direct.\n",
    "    final_model.fit(\n",
    "        X_train_full, y_train_full,\n",
    "    )\n",
    "    \n",
    "    # Prédictions sur le jeu de test\n",
    "    test_preds = final_model.predict_proba(X_test)[:, 1]\n",
    "\n",
    "    # --- 4. CRÉATION DU FICHIER DE SOUMISSION ---\n",
    "    submission['TARGET'] = test_preds\n",
    "    submission_filename = f'submission_optimized_auc_0.7614_{pd.Timestamp.now().strftime(\"%Y%m%d_%H%M\")}.csv'\n",
    "    submission.to_csv(submission_filename, index=False)\n",
    "    \n",
    "    print(f\"\\nSubmission file created: {submission_filename}\")\n",
    "    \n",
    "    # --- 5. LOGGING FINAL DANS MLflow ---\n",
    "    # Loguer les paramètres complets du modèle final\n",
    "    mlflow.log_params(final_model.get_params())\n",
    "    \n",
    "    # Loguer le modèle final lui-même\n",
    "    mlflow.lightgbm.log_model(\n",
    "        final_model.booster_, \n",
    "        artifact_path=\"final_model_artifact\",\n",
    "        registered_model_name=\"HomeCredit_LGBM_FINAL\"\n",
    "    )\n",
    "\n",
    "    # Loguer le fichier de soumission comme artefact\n",
    "    mlflow.log_artifact(submission_filename)\n",
    "\n",
    "print(\"\\n--- Final Model Training and Submission Completed ---\")\n",
    "print(\"Votre fichier de soumission est prêt à être envoyé à Kaggle !\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
